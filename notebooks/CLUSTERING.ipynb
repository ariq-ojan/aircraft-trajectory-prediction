{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ed34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import toolkits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn . manifold import TSNE\n",
    "import os\n",
    "from sklearn . cluster import DBSCAN\n",
    "import matplotlib . pyplot as plt\n",
    "from sklearn . cluster import KMeans\n",
    "from sklearn . metrics import silhouette_samples , silhouette_score\n",
    "from sklearn . preprocessing import MinMaxScaler\n",
    "import csv\n",
    "from sklearn . neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38892c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the transformed data from the CSV file\n",
    "input_file = \"path/to/file\" # Input file directory\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Initialize a dictionary to store the feature vectors\n",
    "flight_feature_vectors = {}\n",
    "\n",
    "# Iterate through each row in the dataframe and create feature vectors for each flight\n",
    "for flight_id, data in df.groupby(\"flight_id\"):\n",
    "    lat_lon_pairs = data[[\"lat_rad\", \"lon_rad\"]].values.flatten()\n",
    "    flight_feature_vectors[flight_id] = lat_lon_pairs\n",
    "\n",
    "# Combine all feature vectors into a single numpy array\n",
    "all_feature_vectors = np.array(list(flight_feature_vectors.values()))\n",
    "print(all_feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eef257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE to reduce the 2465 lat_rad and lon_rad timesteps\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_feature_vectors = tsne.fit_transform(all_feature_vectors)\n",
    "\n",
    "# Normalize the reduced lat_rad and lon_rad values using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "normalized_feature_vectors = scaler.fit_transform (reduced_feature_vectors)\n",
    "\n",
    "# Print the reduced feature vectors for each flight\n",
    "for i, flight_id in enumerate(flight_feature_vectors.keys()):\n",
    "    lat_rad, lon_rad = normalized_feature_vectors [i]\n",
    "    print (f\"{ flight_id}_feature_vector = [{lat_rad}, {lon_rad}]\")\n",
    "\n",
    "# Calculate the within - cluster sum of squares (WSS) for different values of K\n",
    "K_values = range (1,10) # Test K from 1 to 10\n",
    "wss_values = []\n",
    "for K in K_values:\n",
    "    kmeans = KMeans(n_clusters=K, random_state= 42)\n",
    "    kmeans.fit(normalized_feature_vectors)\n",
    "    wss_values.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the WSS values against different values of K\n",
    "plt.figure(figsize =(10, 6))\n",
    "plt.plot(K_values, wss_values , marker ='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Within - Cluster Sum of Squares (WSS )')\n",
    "plt.title('Elbow Method for Optimal K in K- Means')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325875ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate silhouette scores for different values of K\n",
    "K_values = range(2, 11) # Test K from 2 to 10\n",
    "silhouette_scores = []\n",
    "for K in K_values :\n",
    "    kmeans = KMeans (n_clusters=K, random_state =42)\n",
    "    cluster_labels = kmeans.fit_predict(normalized_feature_vectors)\n",
    "    silhouette_avg = silhouette_score(normalized_feature_vectors, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    print (f\" Silhouette Score for K={K}: { silhouette_avg }\")\n",
    "\n",
    "# Plot the silhouette scores against different values of K\n",
    "plt.figure(figsize =(10, 6))\n",
    "plt.plot(K_values, silhouette_scores , marker ='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Method for Optimal K in K- Means ')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the reduced feature vectors on a 2D scatter plot\n",
    "plt.figure (figsize =(10, 6))\n",
    "for i, flight_id in enumerate (flight_feature_vectors.keys()):\n",
    "    lat_rad, lon_rad = normalized_feature_vectors[i]\n",
    "    plt.scatter( lat_rad , lon_rad , label = flight_id )\n",
    "    \n",
    "plt.xlabel(\"Reduced & Normalized Lat_rad\")\n",
    "plt.ylabel(\"Reduced & Normalized Lon_rad\")\n",
    "plt.title(\"t-SNE Visualization of Flight Trajectories\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Cluster Values\n",
    "K = 6 #Adjust and change according to WSS and Silhouette scores\n",
    "iterations = 500 #Adjust and tune accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d81004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K- means clustering\n",
    "kmeans = KMeans (n_clusters =K, max_iter = iterations, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(reduced_feature_vectors)\n",
    "\n",
    "# Calculate silhouette scores for each data point\n",
    "silhouette_scores = silhouette_samples (reduced_feature_vectors, cluster_labels)\n",
    "\n",
    "# Calculate the average silhouette score for the entire clustering\n",
    "avg_silhouette_score = silhouette_score (reduced_feature_vectors, cluster_labels)\n",
    "\n",
    "# Print the average silhouette score\n",
    "print ( f\" Average Silhouette Score for K={K}: { avg_silhouette_score }\")\n",
    "\n",
    "# Define colors for each cluster\n",
    "colors = ['red', 'green', 'navy', 'brown', 'orange', 'purple', 'black']\n",
    "\n",
    "# Get unique cluster labels\n",
    "unique_labels = np.unique(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters and centroids\n",
    "plt.figure (figsize =(10, 6))\n",
    "for i, flight_id in enumerate (flight_feature_vectors.keys()):\n",
    "    lat_rad, lon_rad = normalized_feature_vectors[i]\n",
    "    cluster_label = cluster_labels [i]\n",
    "    plt.scatter(lat_rad, lon_rad, color = colors [cluster_label], label=f\"{flight_id } - Cluster {cluster_label}\")\n",
    "\n",
    "# Add legend for each cluster\n",
    "for label in unique_labels :\n",
    "    plt.scatter ([], [], color = colors [ label ], label =f\" Cluster { label }\")\n",
    "plt.xlabel(\"Lat_rad\")\n",
    "plt.ylabel(\"Lon_rad\")\n",
    "plt.title(\"Normalized Flight Data Clustering Result\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the centroids of the clusters\n",
    "centroids = kmeans.cluster_centers_\n",
    "normalized_centroids = scaler . transform ( centroids )\n",
    "plt.scatter(normalized_centroids[:, 0], normalized_centroids[:, 1], marker ='x', color ='red', s=200, label ='Centroids')\n",
    "plt.xlabel(\"Reduced Lat_rad\")\n",
    "plt.ylabel(\"Reduced Lon_rad\")\n",
    "plt.title(f\"K- means Clustering Centroid with K={K}\")\n",
    "plt.legend ()\n",
    "plt.grid ( True )\n",
    "\n",
    "# Set the same limits as the previous plot\n",
    "plt.xlim(plt.gca().get_xlim())\n",
    "plt.ylim(plt.gca().get_ylim())\n",
    "plt.show()\n",
    "\n",
    "# Get the cluster labels and data points\n",
    "cluster_labels = kmeans.labels_\n",
    "data_points = reduced_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c07dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance of each cluster\n",
    "cluster_variances = []\n",
    "for label in unique_labels :\n",
    "    cluster_data_points = data_points [cluster_labels == label]\n",
    "    cluster_mean = np.mean(cluster_data_points, axis =0)\n",
    "    cluster_variance = np.mean(np.sum((cluster_data_points - cluster_mean) ** 2, axis =1))\n",
    "    cluster_variances.append(cluster_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19956714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the variances\n",
    "plt.figure(figsize =(10, 6))\n",
    "plt.bar(unique_labels, cluster_variances)\n",
    "plt.xlabel(\"Cluster Label\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.title(f\"Variance of each cluster with K={K}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Create a dictionary to store cluster information\n",
    "cluster_info = {f\" Cluster_ {i}\": [] for i in range ( K )}\n",
    "\n",
    "# Group flight IDs based on their cluster labels\n",
    "for i, (flight_id, _) in enumerate (flight_feature_vectors.items()):\n",
    "    cluster_info [f\" Cluster_ {cluster_labels [i]}\"]. append (flight_id)\n",
    "\n",
    "# Find the maximum length of lists in the dictionary\n",
    "max_length = max(len(ids) for ids in cluster_info.values())\n",
    "\n",
    "# Pad the lists with an empty string to make them of equal length\n",
    "for ids in cluster_info.values ():\n",
    "    ids.extend([''] * (max_length - len(ids)))\n",
    "              \n",
    "# Convert the cluster_info dictionary to a pandas DataFrame\n",
    "cluster_df = pd.DataFrame(cluster_info)\n",
    "\n",
    "# Save the cluster information to a CSV file\n",
    "output_file = #Put output directory\n",
    "cluster_df.to_csv(output_file, index = False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
